{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGNORE this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in c:\\python311\\lib\\site-packages (2.9.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('creds.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    access_key = config['aws_access_key_id']\n",
    "    secret_key = config['aws_secret_access_key']\n",
    "    api_access_key = config['api_key']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"capstone-etl-bucket\"\n",
    "csv_file_path = \"weather_data.csv\"\n",
    "s3_key = \"weather_today\"\n",
    "aws_s3_region = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define AWS and Redshift connection details\n",
    "AWS_ACCESS_KEY = access_key\n",
    "AWS_SECRET_KEY = secret_key\n",
    "REDSHIFT_HOST = 'capstone-project.cedwcaggje2k.us-east-1.redshift.amazonaws.com:5439/mydb'\n",
    "REDSHIFT_PORT = '5439'\n",
    "REDSHIFT_DBNAME = 'mydb'\n",
    "REDSHIFT_USER = 'dokes'\n",
    "REDSHIFT_PASSWORD = 'Password1002'\n",
    "IAM_ROLE = 'dokes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 bucket details\n",
    "S3_BUCKET = bucket_name\n",
    "S3_KEY = s3_key\n",
    "REGION =   aws_s3_region\n",
    "\n",
    "# Redshift table details\n",
    "TABLE_NAME = 'your_redshift_table_name'\n",
    "\n",
    "# Establish connection to Redshift\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=REDSHIFT_DBNAME,\n",
    "        user=REDSHIFT_USER,\n",
    "        password=REDSHIFT_PASSWORD,\n",
    "        host=REDSHIFT_HOST,\n",
    "        port=REDSHIFT_PORT\n",
    "    )\n",
    "    print(\"Connected to Redshift successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Unable to connect to Redshift: {e}\")\n",
    "\n",
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Construct the COPY command\n",
    "copy_command = f\"\"\"\n",
    "COPY {TABLE_NAME}\n",
    "FROM 's3://{S3_BUCKET}/{S3_KEY}'\n",
    "IAM_ROLE '{IAM_ROLE}'\n",
    "REGION '{REGION}'\n",
    "FORMAT AS CSV\n",
    "IGNOREHEADER 1\n",
    "\"\"\"\n",
    "\n",
    "# Execute the COPY command\n",
    "try:\n",
    "    cur.execute(copy_command)\n",
    "    conn.commit()\n",
    "    print(\"Data copied to Redshift successfully!\")\n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"Error executing COPY command: {e}\")\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
